# Quick Start - Äiá»ƒm danh KhuÃ´n máº·t

## ğŸš€ Báº¯t Ä‘áº§u nhanh trong 5 bÆ°á»›c

### BÆ°á»›c 1: Táº£i Model (2 phÃºt)

```bash
# Táº£i model MobileFaceNet
cd assets/models

# Option A: Tá»« GitHub
# Truy cáº­p: https://github.com/sirius-ai/MobileFaceNet_TF/releases
# Download file: mobilefacenet.tflite

# Option B: Tá»« Google Drive (náº¿u cÃ³)
# Download vÃ  Ä‘áº·t vÃ o thÆ° má»¥c nÃ y

# Kiá»ƒm tra file Ä‘Ã£ cÃ³
ls mobilefacenet.tflite
```

### BÆ°á»›c 2: Build App (3 phÃºt)

```bash
# Clean project
flutter clean

# Get dependencies
flutter pub get

# Build APK
flutter build apk --debug

# Hoáº·c run trá»±c tiáº¿p
flutter run
```

### BÆ°á»›c 3: Setup Backend API (10 phÃºt)

Táº¡o file `face_attendance_api.py`:

```python
from flask import Flask, request, jsonify
import numpy as np
import json

app = Flask(__name__)

# Mock database (thay báº±ng DB tháº­t)
EMPLOYEES = {
    'NV001': {
        'name': 'Nguyá»…n VÄƒn A',
        'embedding': [0.1] * 192  # Thay báº±ng embedding tháº­t
    }
}

def cosine_similarity(emb1, emb2):
    emb1 = np.array(emb1)
    emb2 = np.array(emb2)
    return np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))

@app.route('/api', methods=['POST'])
def api():
    data = request.json
    if data['command'] == 'checkFaceAttendance':
        embedding = data['DATA']['face_embedding']
        
        # TÃ¬m match
        best_match = None
        best_score = 0
        
        for code, emp in EMPLOYEES.items():
            score = cosine_similarity(embedding, emp['embedding'])
            if score > best_score and score >= 0.6:
                best_match = (code, emp['name'], score)
                best_score = score
        
        if best_match:
            return jsonify({
                'tk_status': 'OK',
                'message': 'Äiá»ƒm danh thÃ nh cÃ´ng',
                'employee_code': best_match[0],
                'employee_name': best_match[1],
                'attendance_time': data['DATA']['timestamp']
            })
        else:
            return jsonify({
                'tk_status': 'NG',
                'message': 'KhÃ´ng tÃ¬m tháº¥y trong database'
            })
    
    return jsonify({'tk_status': 'NG', 'message': 'Unknown command'})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=3007)
```

Cháº¡y server:
```bash
pip install flask numpy
python face_attendance_api.py
```

### BÆ°á»›c 4: Cáº¥u hÃ¬nh Server IP (1 phÃºt)

Trong app, set server IP:
- Má»Ÿ Settings
- Chá»n TEST_SERVER hoáº·c nháº­p IP: `http://YOUR_IP:3007/api`

### BÆ°á»›c 5: Test (2 phÃºt)

1. Má»Ÿ app
2. Navigate Ä‘áº¿n mÃ n hÃ¬nh "Äiá»ƒm danh báº±ng khuÃ´n máº·t"
3. ÄÆ°a máº·t vÃ o khung hÃ¬nh
4. Xem káº¿t quáº£

## ğŸ“ Enrollment - ÄÄƒng kÃ½ khuÃ´n máº·t

### Script Python Ä‘á»ƒ extract embedding tá»« áº£nh

```python
import cv2
import numpy as np
from mtcnn import MTCNN
import tensorflow as tf

# Load model
interpreter = tf.lite.Interpreter(model_path='mobilefacenet.tflite')
interpreter.allocate_tensors()

# Load face detector
detector = MTCNN()

def extract_face_embedding(image_path):
    # Load image
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Detect face
    faces = detector.detect_faces(img_rgb)
    if not faces:
        return None
    
    # Get first face
    x, y, w, h = faces[0]['box']
    face = img_rgb[y:y+h, x:x+w]
    
    # Resize to 112x112
    face = cv2.resize(face, (112, 112))
    
    # Normalize
    face = (face - 127.5) / 127.5
    face = np.expand_dims(face, axis=0).astype(np.float32)
    
    # Run inference
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    interpreter.set_tensor(input_details[0]['index'], face)
    interpreter.invoke()
    
    embedding = interpreter.get_tensor(output_details[0]['index'])
    return embedding[0].tolist()

# Extract embedding
embedding = extract_face_embedding('employee_photo.jpg')
print(json.dumps(embedding))

# Save to database
# INSERT INTO employee_faces (employee_code, employee_name, face_embedding)
# VALUES ('NV001', 'Nguyá»…n VÄƒn A', '[...]')
```

## ğŸ”§ Troubleshooting nhanh

### Lá»—i: "Lá»—i load model"
```bash
# Kiá»ƒm tra file model
ls assets/models/mobilefacenet.tflite

# Náº¿u khÃ´ng cÃ³, táº£i láº¡i
cd assets/models
# Download model vÃ o Ä‘Ã¢y

# Clean vÃ  rebuild
flutter clean && flutter pub get && flutter run
```

### Lá»—i: "KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t"
- Báº­t Ä‘Ã¨n, Ä‘áº£m báº£o Ã¡nh sÃ¡ng Ä‘á»§
- NhÃ¬n tháº³ng vÃ o camera
- Khoáº£ng cÃ¡ch 30-50cm
- KhÃ´ng Ä‘eo kháº©u trang/kÃ­nh rÃ¢m

### Lá»—i: "Lá»—i káº¿t ná»‘i API"
```bash
# Kiá»ƒm tra server Ä‘ang cháº¡y
curl http://YOUR_IP:3007/api

# Kiá»ƒm tra firewall
# Windows: Allow port 3007
# Linux: sudo ufw allow 3007

# Test vá»›i Postman
POST http://YOUR_IP:3007/api
Body: {"command": "checkFaceAttendance", "DATA": {...}}
```

### Lá»—i: "KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c"
- Kiá»ƒm tra Ä‘Ã£ enrollment chÆ°a
- Thá»­ giáº£m threshold xuá»‘ng 0.5
- Verify embedding trong database
- Re-enroll vá»›i áº£nh cháº¥t lÆ°á»£ng tá»‘t hÆ¡n

## ğŸ“Š Test Checklist

- [ ] Model file tá»“n táº¡i: `assets/models/mobilefacenet.tflite`
- [ ] App build thÃ nh cÃ´ng
- [ ] Camera permissions granted
- [ ] Camera khá»Ÿi táº¡o OK
- [ ] Face detection hoáº¡t Ä‘á»™ng (khung xanh hiá»‡n ra)
- [ ] Backend API running
- [ ] Server IP configured Ä‘Ãºng
- [ ] Test employee Ä‘Ã£ enrollment
- [ ] API response OK
- [ ] Dialog hiá»ƒn thá»‹ káº¿t quáº£

## ğŸ¯ Demo Flow

```
1. User má»Ÿ app
   â†“
2. Navigate to "Äiá»ƒm danh báº±ng khuÃ´n máº·t"
   â†“
3. Camera tá»± Ä‘á»™ng báº­t
   Status: "ÄÆ°a khuÃ´n máº·t vÃ o khung hÃ¬nh Ä‘á»ƒ Ä‘iá»ƒm danh"
   â†“
4. User Ä‘Æ°a máº·t vÃ o khung oval
   â†“
5. Face detected (khung xanh hiá»‡n ra)
   Status: "PhÃ¡t hiá»‡n 1 khuÃ´n máº·t. Äang xá»­ lÃ½..."
   â†“
6. Extract embedding (~100ms)
   Status: "Äang kiá»ƒm tra vá»›i database..."
   â†“
7. Call API (~300ms)
   â†“
8. Show result:
   - Success: Dialog "Äiá»ƒm danh thÃ nh cÃ´ng"
   - Failure: "KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c"
   â†“
9. Cooldown 3 giÃ¢y
   â†“
10. Quay láº¡i bÆ°á»›c 3
```

## ğŸ“š TÃ i liá»‡u chi tiáº¿t

- `FACE_RECOGNITION_SETUP.md` - Setup Ä‘áº§y Ä‘á»§
- `API_BACKEND_REFERENCE.md` - API implementation
- `IMPLEMENTATION_SUMMARY.md` - Technical details
- `assets/models/README.md` - Model info

## ğŸ’¡ Tips

1. **Enrollment tá»‘t = Recognition tá»‘t**
   - Chá»¥p 5-10 áº£nh tá»« cÃ¡c gÃ³c
   - Ãnh sÃ¡ng tá»‘t, khÃ´ng bÃ³ng máº·t
   - Nhiá»u biá»ƒu cáº£m khÃ¡c nhau

2. **Tá»‘i Æ°u threshold**
   - Báº¯t Ä‘áº§u vá»›i 0.6
   - Náº¿u nhiá»u false reject â†’ giáº£m xuá»‘ng 0.5
   - Náº¿u nhiá»u false accept â†’ tÄƒng lÃªn 0.7

3. **Performance**
   - Medium resolution = cÃ¢n báº±ng tá»‘t
   - High resolution = cháº­m hÆ¡n nhÆ°ng chÃ­nh xÃ¡c hÆ¡n
   - Low resolution = nhanh nhÆ°ng kÃ©m chÃ­nh xÃ¡c

4. **Security**
   - LuÃ´n dÃ¹ng HTTPS
   - Validate token
   - Rate limiting
   - Log táº¥t cáº£ attempts

## ğŸ†˜ Support

Náº¿u cáº§n help:
1. Check logs: `flutter logs`
2. Review documentation files
3. Test API vá»›i Postman
4. Verify model file
5. Check permissions

---

**Thá»i gian setup tá»•ng**: ~20 phÃºt  
**Äá»™ khÃ³**: Trung bÃ¬nh  
**Prerequisites**: Flutter, Python, Basic ML knowledge
